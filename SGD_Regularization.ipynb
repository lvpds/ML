{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_9_Prasad_26Oct2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443f36df-16ed-4ce1-e242-a1d98efde8cf"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c40861-ba3a-4fc0-97c6-7d57fab58b35"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cb017a-fa01-47bb-9d79-18d9854e3247"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be50b9a-eff8-4ad1-a602-d8c0c51b6fb1"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 14 epochs took 0.12 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd77c0d-58a2-45c2-dac0-737e37d22b2a"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
              "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
              "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
              " (1, 15),\n",
              " array([-1.30580538]))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "\n",
        "    w = np.zeros_like(dim)\n",
        "    b = 0\n",
        "    \n",
        "    return w,b"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329dae7a-3c2f-438d-84b4-a5cf726ada54"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d43635-725d-4844-8472-0c1bf71aefa7"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "import math\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    sigmoid_z = 1/(1+math.exp(-1*z))\n",
        "    return sigmoid_z"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172b8ce5-c061-4e38-c008-2c0e0cc8287a"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert val==0.8807970779778823\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    temp = 0\n",
        "    for i in range(len(y_true)):\n",
        "      y_pred_float = y_pred.astype(np.float)\n",
        "      if y_pred_float[i]<=0.0 or y_pred_float[i]==1.0:\n",
        "        if y_pred_float[i]==0.0:\n",
        "          y_pred_float[i] = 1e-12\n",
        "        elif y_pred_float[i]==1.0:\n",
        "          y_pred_float[i] = 1-1e-12\n",
        "        else:\n",
        "          y_pred_float[i] = abs(y_pred_float[i])\n",
        "      temp = temp+((y_true[i]*math.log10(y_pred_float[i]))+((1-y_true[i])*math.log10(1-y_pred_float[i])))\n",
        "    loss = -1*(temp/len(y_true))\n",
        "    return loss\n",
        "        \n",
        "    "
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bfe810-5bfc-4537-dde3-a718333911d7"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert loss==0.07644900402910389\n",
        "  return True\n",
        "  print(loss)\n",
        "true=[1,1,0,1,0]\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = x*(y-sigmoid(np.matmul(w.transpose(),x)+b))-(alpha/N)*w\n",
        "    return dw"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04bb379-8477-426a-e256-9c3c57ebc226"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     db = y-sigmoid(np.matmul(w.transpose(),x)+b) \n",
        "     return db"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b76a1b1-d770-43c0-9bcc-450008b98d9f"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a40da6-c5e6-41e5-a659-224b4984c57e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))\n",
        "\n",
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    # for every epoch\n",
        "        # for every data point(X_train,y_train)\n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "           #update w, b\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the train loss values in a list\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the test loss values in a list\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
        "    w,b=initialize_weights(X_train[0])\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    for j in tqdm(range(epochs)):\n",
        "      for i in range(len(X_train)):\n",
        "        dw = gradient_dw(X_train[i],y_train[i],w,b,alpha,len(X_train))\n",
        "        db = gradient_db(X_train[i],y_train[i],w,b)\n",
        "        w = w+eta0*dw\n",
        "        b = b+eta0*db\n",
        "      y_true_train = y_train\n",
        "      y_pred_train = pred(w,b, X_train)  \n",
        "      loss = logloss(y_true_train,y_pred_train)\n",
        "      train_loss.append(loss)\n",
        "      y_true_test = y_test\n",
        "      y_pred_test = pred(w,b, X_test)  \n",
        "      loss = logloss(y_true_test,y_pred_test)\n",
        "      test_loss.append(loss)\n",
        "    plt.plot(list(range(epochs)),train_loss,label=\"Train dataset loss\") \n",
        "    plt.plot(list(range(epochs)),test_loss,label=\"Test dataset loss\") \n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return w,b"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6978933333333335\n",
            "1.6986400000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "75cf4c09-ed20-4856-fccb-ee76134fdb10"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=14\n",
        "w,b=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:52<00:00,  3.72s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.89482323  0.63922609 -0.07409042  0.63113611 -0.38279876  0.9346933\n",
            " -0.89664514 -0.07124397  0.41113377  0.41550075  0.24845771  0.05300616\n",
            " -0.08703024  0.53952896  0.06749254]\n",
            "-1.3030058566516542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d27d27b-99cd-4bf6-e075-bd4c3186f420"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-4.75139040e-03,  7.60245639e-03,  1.85102713e-03,\n",
              "          6.50362355e-05,  1.54498740e-03,  2.34086809e-03,\n",
              "         -9.09928936e-04,  2.16124544e-03,  5.21959720e-03,\n",
              "         -4.49834999e-03,  1.23628554e-03,  2.54417563e-03,\n",
              "          1.74962845e-03, -1.28756176e-03,  1.05365463e-03]]),\n",
              " array([0.00279952]))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k28U1xDsLIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMokBfs3-2PY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}